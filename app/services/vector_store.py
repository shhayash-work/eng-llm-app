"""
ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹
"""
import os
import sys
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path

# SQLiteã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«pysqlite3ã‚’ä½¿ç”¨
try:
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

import chromadb
from chromadb.config import Settings
from langchain.text_splitter import RecursiveCharacterTextSplitter
import ollama
from app.config.settings import (
    VECTOR_STORE_DIR, 
    EMBEDDING_MODEL, 
    CHUNK_SIZE, 
    CHUNK_OVERLAP
)

logger = logging.getLogger(__name__)

class VectorStoreService:
    """ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self, create_mode: bool = False):
        """
        VectorStoreServiceåˆæœŸåŒ–
        
        Args:
            create_mode (bool): True=äº‹å‰å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆå‰Šé™¤ãƒ»å†ä½œæˆï¼‰, False=èª­ã¿è¾¼ã¿ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ—¢å­˜åˆ©ç”¨ï¼‰
        """
        self.vector_store_dir = VECTOR_STORE_DIR
        self.collection_name = "construction_documents"
        self.create_mode = create_mode
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.vector_store_dir, exist_ok=True)
        
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.client = chromadb.PersistentClient(
            path=str(self.vector_store_dir),
            settings=Settings(anonymized_telemetry=False)
        )
        
        # OllamaåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆäº‹å‰å‡¦ç†æ™‚ã®ã¿å¿…è¦ï¼‰
        if create_mode:
            self.embedding_model_name = EMBEDDING_MODEL
            self.ollama_client = ollama.Client()
            
            # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å™¨åˆæœŸåŒ–ï¼ˆäº‹å‰å‡¦ç†æ™‚ã®ã¿ï¼‰
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=CHUNK_SIZE,
                chunk_overlap=CHUNK_OVERLAP,
                separators=["\n\n", "\n", "ã€‚", "ã€", " ", ""]
            )
        
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—ã¾ãŸã¯ä½œæˆ
        self._setup_collection()
    
    def _setup_collection(self):
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:
            if self.create_mode:
                # äº‹å‰å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: å‰Šé™¤ãƒ»å†ä½œæˆ
                try:
                    self.client.delete_collection(name=self.collection_name)
                    logger.info(f"ğŸ—‘ï¸ Deleted existing collection: {self.collection_name}")
                except Exception:
                    pass  # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç„¡è¦–
                
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={"description": f"å»ºè¨­æ–‡æ›¸ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ ({EMBEDDING_MODEL})"}
                )
                logger.info(f"âœ¨ New collection created for {EMBEDDING_MODEL}: {self.collection_name}")
            else:
                # èª­ã¿è¾¼ã¿ãƒ¢ãƒ¼ãƒ‰: æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å†åˆ©ç”¨
                try:
                    self.collection = self.client.get_collection(name=self.collection_name)
                    logger.info(f"âš¡ Reusing existing collection: {self.collection_name}")
                except Exception:
                    # æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆ
                    logger.warning(f"âš ï¸ Collection {self.collection_name} not found. Creating new one.")
                    self.collection = self.client.create_collection(
                        name=self.collection_name,
                        metadata={"description": f"å»ºè¨­æ–‡æ›¸ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ ({EMBEDDING_MODEL})"}
                    )
                    logger.info(f"ğŸ†• Created new collection: {self.collection_name}")
        except Exception as e:
            logger.error(f"Failed to setup collection: {e}")
            raise
    
    def add_document(self, content: str, metadata: Dict[str, Any]) -> bool:
        """æ–‡æ›¸ã‚’ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«è¿½åŠ """
        try:
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ç¢ºèªã¨å†å–å¾—
            try:
                self.collection = self.client.get_collection(self.collection_name)
            except Exception:
                # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆ
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={"description": f"å»ºè¨­æ–‡æ›¸ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ ({EMBEDDING_MODEL})"}
                )
                logger.info(f"Collection recreated: {self.collection_name}")
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            chunks = self.text_splitter.split_text(content)
            
            # Ollamaã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ
            embeddings = []
            for chunk in chunks:
                response = self.ollama_client.embeddings(
                    model=self.embedding_model_name,
                    prompt=chunk
                )
                embeddings.append(response['embedding'])
            
            # ãƒãƒ£ãƒ³ã‚¯IDã‚’ç”Ÿæˆ
            doc_id = metadata.get('file_name', 'unknown')
            chunk_ids = [f"{doc_id}_chunk_{i}" for i in range(len(chunks))]
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«è¤‡è£½
            chunk_metadatas = []
            for i, chunk in enumerate(chunks):
                chunk_metadata = metadata.copy()
                chunk_metadata.update({
                    'chunk_id': i,
                    'chunk_text': chunk[:100] + "..." if len(chunk) > 100 else chunk
                })
                chunk_metadatas.append(chunk_metadata)
            
            # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
            self.collection.add(
                embeddings=embeddings,
                documents=chunks,
                metadatas=chunk_metadatas,
                ids=chunk_ids
            )
            
            logger.info(f"Document added: {doc_id} ({len(chunks)} chunks)")
            return True
            
        except Exception as e:
            logger.error(f"Failed to add document: {e}")
            return False
    
    def search_similar_documents(
        self, 
        query: str, 
        n_results: int = 5,
        filter_metadata: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢"""
        try:
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ç¢ºèª
            try:
                self.collection = self.client.get_collection(self.collection_name)
            except Exception:
                logger.warning(f"Collection {self.collection_name} not found")
                return []
            
            # ã‚¯ã‚¨ãƒªã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆ
            # Ollamaã‚¯ã‚¨ãƒªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆ
            response = self.ollama_client.embeddings(
                model=self.embedding_model_name,
                prompt=query
            )
            query_embedding = response['embedding']
            
            # æ¤œç´¢å®Ÿè¡Œ
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                where=filter_metadata
            )
            
            # çµæœã‚’æ•´å½¢
            search_results = []
            for i in range(len(results['documents'][0])):
                result = {
                    'content': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'distance': results['distances'][0][i] if 'distances' in results else 0.0,
                    'id': results['ids'][0][i]
                }
                search_results.append(result)
            
            logger.info(f"Search completed: {len(search_results)} results")
            return search_results
            
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []
    
    def get_document_count(self) -> int:
        """ä¿å­˜ã•ã‚Œã¦ã„ã‚‹æ–‡æ›¸æ•°ã‚’å–å¾—"""
        try:
            return self.collection.count()
        except Exception as e:
            logger.error(f"Failed to get document count: {e}")
            return 0
    
    def delete_document(self, doc_id: str) -> bool:
        """æ–‡æ›¸ã‚’å‰Šé™¤"""
        try:
            # doc_idã§å§‹ã¾ã‚‹ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤
            all_results = self.collection.get()
            ids_to_delete = [
                id for id in all_results['ids'] 
                if id.startswith(f"{doc_id}_chunk_")
            ]
            
            if ids_to_delete:
                self.collection.delete(ids=ids_to_delete)
                logger.info(f"Document deleted: {doc_id} ({len(ids_to_delete)} chunks)")
                return True
            else:
                logger.warning(f"Document not found: {doc_id}")
                return False
                
        except Exception as e:
            logger.error(f"Failed to delete document: {e}")
            return False
    
    def clear_all_documents(self) -> bool:
        """ã™ã¹ã¦ã®æ–‡æ›¸ã‚’å‰Šé™¤"""
        try:
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¦å†ä½œæˆ
            self.client.delete_collection(self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"description": "å»ºè¨­æ–‡æ›¸ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢"}
            )
            logger.info("All documents cleared")
            return True
            
        except Exception as e:
            logger.error(f"Failed to clear documents: {e}")
            return False