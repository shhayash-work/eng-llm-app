"""
æ–‡æ›¸å‡¦ç†ã‚µãƒ¼ãƒ“ã‚¹
"""
import os
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
from docx import Document
try:
    import PyPDF2
except ImportError:
    try:
        import pypdf as PyPDF2
    except ImportError:
        PyPDF2 = None

from openpyxl import load_workbook

from app.models.report import DocumentReport, ReportType, AnalysisResult, AnomalyDetection
from app.services.llm_service import LLMService
from app.services.vector_store import VectorStoreService
from app.config.settings import SHAREPOINT_DOCS_DIR

logger = logging.getLogger(__name__)

if PyPDF2 is None:
    logger.warning("PyPDF2/pypdf not available. PDF reading will be disabled.")

def calculate_risk_level_enum(urgency_score: int) -> 'RiskLevel':
    """urgency_scoreã‹ã‚‰è¡¨ç¤ºç”¨ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’ç®—å‡º"""
    from app.models.report import RiskLevel
    if urgency_score >= 7:
        return RiskLevel.HIGH
    elif urgency_score >= 4:
        return RiskLevel.MEDIUM
    else:
        return RiskLevel.LOW

class DocumentProcessor:
    """æ–‡æ›¸å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, llm_provider: Optional[str] = None, create_vector_store: bool = False):
        self.llm_service = LLMService(provider=llm_provider)
        self.vector_store = VectorStoreService(create_mode=create_vector_store)
        
    def process_directory(self, directory_path: Path) -> List[DocumentReport]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨æ–‡æ›¸ã‚’å‡¦ç†"""
        reports = []
        
        # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
        supported_extensions = {'.txt', '.pdf', '.docx', '.xlsx'}
        
        for file_path in directory_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                try:
                    report = self.process_single_document(file_path)
                    if report:
                        reports.append(report)
                        logger.info(f"Processed: {file_path.name}")
                except Exception as e:
                    logger.error(f"Failed to process {file_path}: {e}")
        
        return reports
    
    def process_single_document(self, file_path: Path) -> Optional[DocumentReport]:
        """å˜ä¸€æ–‡æ›¸ã‚’å‡¦ç†ï¼ˆçµ±åˆåˆ†æ1å›ã®ã¿ï¼‰"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
            content = self._read_file_content(file_path)
            if not content:
                return None
            
            # ğŸ¤– çµ±åˆLLMåˆ†æã‚’å®Ÿè¡Œï¼ˆãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—åˆ¤å®š + ãƒ¡ã‚¤ãƒ³åˆ†æ + åˆ†é¡å›°é›£æ¤œçŸ¥ã‚’1å›ã§ï¼‰
            llm_result = self.llm_service.analyze_document(content)
            if not llm_result:
                logger.error(f"çµ±åˆLLMåˆ†æãŒå¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ãªã—ï¼‰: {file_path.name}")
                return None
            
            # DocumentReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆï¼ˆçµ±åˆåˆ†æçµæœã‚’ä½¿ç”¨ï¼‰
            report = self._create_report_from_unified_analysis(file_path, content, llm_result)
            
            # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
            self._add_to_vector_store(report)
            
            return report
            
        except Exception as e:
            logger.error(f"Document processing failed: {e}")
            return None
    
    def _read_file_content(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿"""
        extension = file_path.suffix.lower()
        
        try:
            if extension == '.txt':
                return self._read_text_file(file_path)
            elif extension == '.pdf':
                return self._read_pdf_file(file_path)
            elif extension == '.docx':
                return self._read_docx_file(file_path)
            elif extension == '.xlsx':
                return self._read_xlsx_file(file_path)
            else:
                logger.warning(f"Unsupported file type: {extension}")
                return ""
        except Exception as e:
            logger.error(f"Failed to read file {file_path}: {e}")
            return ""
    
    def _read_text_file(self, file_path: Path) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        encodings = ['utf-8', 'shift_jis', 'euc-jp', 'iso-2022-jp']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue
        
        # ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§å¤±æ•—ã—ãŸå ´åˆ
        logger.warning(f"Could not decode text file: {file_path}")
        return ""
    
    def _read_pdf_file(self, file_path: Path) -> str:
        """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if PyPDF2 is None:
            logger.warning(f"PDF reading not available for {file_path}")
            return "PDFèª­ã¿è¾¼ã¿æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚PyPDF2ã¾ãŸã¯pypdfã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚"
        
        text = ""
        try:
            with open(file_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\\n"
        except Exception as e:
            logger.error(f"PDF reading failed: {e}")
        return text
    
    def _read_docx_file(self, file_path: Path) -> str:
        """Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ±ç”¨çš„ï¼‰"""
        text = ""
        try:
            doc = Document(file_path)
            
            # æ®µè½ã‚’èª­ã¿è¾¼ã¿
            for paragraph in doc.paragraphs:
                para_text = paragraph.text.strip()
                if para_text:
                    # ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                    para_text = para_text.replace('\\t', ' ')
                    para_text = ' '.join(para_text.split())  # è¤‡æ•°ç©ºç™½ã‚’1ã¤ã«
                    text += para_text + "\\n"
            
            # è¡¨ã‚’èª­ã¿è¾¼ã¿
            for table in doc.tables:
                text += "\\nè¡¨:\\n"
                for row in table.rows:
                    row_data = []
                    for cell in row.cells:
                        cell_text = cell.text.strip()
                        if cell_text:
                            # ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                            cell_text = cell_text.replace('\\n', ' ').replace('\\t', ' ')
                            cell_text = ' '.join(cell_text.split())  # è¤‡æ•°ç©ºç™½ã‚’1ã¤ã«
                            if cell_text not in ['', '-', 'âˆ’', 'è©²å½“ãªã—', 'ãªã—']:
                                row_data.append(cell_text)
                    if row_data:
                        text += " | ".join(row_data) + "\\n"
                        
        except Exception as e:
            logger.error(f"DOCX reading failed: {e}")
        return text
    
    def _read_xlsx_file(self, file_path: Path) -> str:
        """Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ±ç”¨çš„ï¼‰"""
        text = ""
        try:
            workbook = load_workbook(file_path, data_only=True)
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                text += f"\\nã‚·ãƒ¼ãƒˆ: {sheet_name}\\n"
                
                # å…¨ã‚»ãƒ«ã®å†…å®¹ã‚’é †æ¬¡æŠ½å‡º
                for row in sheet.iter_rows(values_only=True):
                    row_values = []
                    for cell_value in row:
                        if cell_value is not None:
                            # ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                            clean_value = str(cell_value).strip()
                            # ä¸è¦æ–‡å­—ã®å‰Šé™¤ï¼ˆæ”¹è¡Œã€ã‚¿ãƒ–ã€ä½™åˆ†ãªç©ºç™½ï¼‰
                            clean_value = clean_value.replace('\\n', ' ').replace('\\t', ' ')
                            clean_value = ' '.join(clean_value.split())  # è¤‡æ•°ç©ºç™½ã‚’1ã¤ã«
                            # ç©ºæ–‡å­—ã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                            if clean_value and clean_value not in ['nan', 'None', 'NULL', '#N/A']:
                                row_values.append(clean_value)
                    
                    if row_values:
                        text += " | ".join(row_values) + "\\n"
                        
        except Exception as e:
            logger.error(f"XLSX reading failed: {e}")
        return text
    
    def _create_report_from_unified_analysis(self, file_path: Path, content: str, llm_result: Dict[str, Any]) -> DocumentReport:
        """çµ±åˆLLMåˆ†æçµæœã‹ã‚‰DocumentReportã‚’ä½œæˆ"""
        from app.models.report import StatusFlag, RiskLevel
        from app.services.project_mapper import ProjectMapper
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã®è¨­å®š
        report_type_str = llm_result.get('report_type', 'OTHER')
        try:
            report_type = ReportType(report_type_str)
        except ValueError:
            logger.warning(f"ç„¡åŠ¹ãªãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—: {report_type_str}ã€OTHERã«è¨­å®š")
            report_type = ReportType.OTHER
        
        # DocumentReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        report = DocumentReport(
            file_path=str(file_path),
            file_name=file_path.name,
            report_type=report_type,
            content=content,
            created_at=datetime.fromtimestamp(file_path.stat().st_mtime)
        )
        
        # ğŸ¤– çµ±åˆåˆ†æçµæœã‚’è¨­å®š
        report.requires_human_review = llm_result.get('requires_human_review', False)
        report.analysis_confidence = llm_result.get('analysis_confidence', 0.0)
        
        # ğŸ†• è©³ç´°ä¿¡é ¼åº¦ãƒ»æ ¹æ‹ æƒ…å ±ã‚’è¨­å®š
        report.analysis_metadata = llm_result.get('analysis_metadata', {})
        
        # é …ç›®åˆ¥ä¿¡é ¼åº¦è©³ç´°ã‚’åé›†
        confidence_details = {}
        evidence_details = {}
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã®ä¿¡é ¼åº¦ãƒ»æ ¹æ‹ 
        confidence_details['report_type'] = llm_result.get('report_type_confidence', 0.0)
        evidence_details['report_type'] = llm_result.get('report_type_evidence', '')
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã®ä¿¡é ¼åº¦ãƒ»æ ¹æ‹ 
        project_info = llm_result.get('project_info', {})
        for field in ['project_id', 'station_name', 'station_number', 'aurora_plan', 'location', 'responsible_person']:
            confidence_key = f'{field}_confidence'
            evidence_key = f'{field}_evidence'
            if confidence_key in project_info:
                confidence_details[field] = project_info[confidence_key]
            if evidence_key in project_info:
                evidence_details[field] = project_info[evidence_key]
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ»å·¥ç¨‹ã®ä¿¡é ¼åº¦ãƒ»æ ¹æ‹ 
        confidence_details['status_flag'] = llm_result.get('status_flag_confidence', 0.0)
        evidence_details['status_flag'] = llm_result.get('status_flag_evidence', '')
        confidence_details['construction_phase'] = llm_result.get('construction_phase_confidence', 0.0)
        evidence_details['construction_phase'] = llm_result.get('construction_phase_evidence', '')
        
        # ç·Šæ€¥åº¦ã‚¹ã‚³ã‚¢ã®ä¿¡é ¼åº¦ãƒ»æ ¹æ‹ 
        confidence_details['urgency_score'] = llm_result.get('urgency_score_confidence', 0.0)
        evidence_details['urgency_score'] = llm_result.get('urgency_score_evidence', '')
        
        # é…å»¶ç†ç”±ã®ä¿¡é ¼åº¦ãƒ»æ ¹æ‹ 
        delay_reasons = llm_result.get('delay_reasons', [])
        if delay_reasons:
            for i, reason in enumerate(delay_reasons):
                confidence_details[f'delay_reason_{i}'] = reason.get('confidence', 0.0)
                evidence_details[f'delay_reason_{i}'] = reason.get('evidence', '')
        
        report.confidence_details = confidence_details
        report.evidence_details = evidence_details
        
        # ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆç›´æ¥ID + ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼‰
        self._apply_project_mapping(report, llm_result)
        
        # ğŸ·ï¸ æ–°ãƒ•ãƒ©ã‚°ä½“ç³»ã®é©ç”¨ï¼ˆç°¡ç•¥åŒ–ï¼‰
        # StatusFlagè¨­å®šï¼ˆLLMã‹ã‚‰ç›´æ¥å–å¾—ï¼‰
        llm_status_flag = llm_result.get('status_flag')
        if llm_status_flag:
            if llm_status_flag == 'åœæ­¢':
                report.status_flag = StatusFlag.STOPPED
            elif llm_status_flag == 'é‡å¤§ãªé…å»¶':
                report.status_flag = StatusFlag.MAJOR_DELAY
            elif llm_status_flag == 'è»½å¾®ãªé…å»¶':
                report.status_flag = StatusFlag.MINOR_DELAY
            elif llm_status_flag == 'é †èª¿':
                report.status_flag = StatusFlag.NORMAL
            else:
                report.status_flag = StatusFlag.NORMAL
        else:
            report.status_flag = StatusFlag.NORMAL
            
        # RiskLevelè¨­å®šï¼ˆurgency_scoreã‹ã‚‰é€£å‹•ãƒ«ãƒ¼ãƒ«ã§ç®—å‡ºï¼‰
        urgency_score = llm_result.get('urgency_score', 1)
        report.urgency_score = urgency_score
        report.risk_level = calculate_risk_level_enum(urgency_score)
        
        # ğŸ†• å ±å‘Šæ›¸ã‚¿ã‚¤ãƒ—ã‹ã‚‰å»ºè¨­å·¥ç¨‹é–¢é€£æ€§ã‚’ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹å‡ºåŠ›
        from app.services.report_type_mapper import ReportTypeMapper
        
        phase_mapping = ReportTypeMapper.get_phase_analysis_for_report(report_type)
        report_type_phase_mapping = llm_result.get('report_type_phase_mapping', phase_mapping.get('report_type_phase_mapping', {}))
        
        # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®æœŸå¾…å·¥ç¨‹ã¨å®Ÿéš›ã®å‡ºåŠ›ã‚’çµ±åˆ
        expected_phase = ReportTypeMapper.get_expected_phase_from_report_type(report_type)
        if report_type_phase_mapping.get('expected_primary_phase') == 'ä¸æ˜' and expected_phase != 'ä¸æ˜':
            report_type_phase_mapping['expected_primary_phase'] = expected_phase
            report_type_phase_mapping['mapping_confidence'] = ReportTypeMapper.get_phase_mapping(report_type).get('confidence', 0.0)
            report_type_phase_mapping['mapping_description'] = ReportTypeMapper.get_phase_mapping(report_type).get('description', '')
        
        # å ±å‘Šæ›¸ã‚¿ã‚¤ãƒ—ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜ï¼ˆçµ±åˆåˆ†æç”¨ï¼‰
        report.report_type_phase_mapping = report_type_phase_mapping
        
        # ä¿¡é ¼åº¦ãƒ»æ ¹æ‹ è©³ç´°ã«è¿½åŠ 
        confidence_details['report_type_phase_mapping'] = report_type_phase_mapping.get('mapping_confidence', 0.0)
        evidence_details['report_type_phase_mapping'] = report_type_phase_mapping.get('mapping_description', '')
        
        # ğŸš§ é…å»¶ç†ç”±æƒ…å ±ã®è¨­å®šï¼ˆ15ã‚«ãƒ†ã‚´ãƒªä½“ç³»ï¼‰
        report.delay_reasons = llm_result.get('delay_reasons', [])
        
        # ğŸ†• LLMã®æŠ½å‡ºçµæœã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ»æ¤œè¨¼ç”¨ï¼‰
        report.llm_extraction_result = llm_result.get('project_info', {})
        
        # current_statuså‡¦ç†å‰Šé™¤: status_flagã§çµ±ä¸€
        
        # ğŸ“‹ AnalysisResultä½œæˆï¼ˆç°¡ç´ åŒ–ï¼‰
        report.analysis_result = AnalysisResult(
            summary=llm_result.get('summary', 'åˆ†æçµæœãªã—'),
            issues=llm_result.get('issues', []),
            key_points=llm_result.get('key_points', []),
            confidence=report.analysis_confidence
        )
        
        # ğŸš¨ ç•°å¸¸æ¤œçŸ¥ã®çµ±åˆï¼ˆåˆ†æå›°é›£åº¦ã¨ã—ã¦æ‰±ã†ï¼‰
        report.anomaly_detection = AnomalyDetection(
            is_anomaly=report.requires_human_review,
            anomaly_description=f"LLMã«ã‚ˆã‚‹åˆ†æå›°é›£åº¦: {'è¦ç¢ºèª' if report.requires_human_review else 'æ­£å¸¸'}",
            confidence=report.analysis_confidence,
            suggested_action="æ‰‹å‹•ç¢ºèªã‚’æ¨å¥¨" if report.requires_human_review else "è‡ªå‹•åˆ†æå®Œäº†",
            requires_human_review=report.requires_human_review,
            similar_cases=[]
        )
        
        # ğŸ” äººçš„ç¢ºèªãƒ•ãƒ©ã‚°ã®è¨­å®š
        self._set_review_flags(report, llm_result)
        
        return report
    
    def _set_review_flags(self, report: DocumentReport, llm_result: Dict[str, Any]):
        """äººçš„ç¢ºèªãƒ•ãƒ©ã‚°ã‚’è¨­å®š"""
        # å ±å‘Šæ›¸å†…å®¹ç¢ºèªãŒå¿…è¦ãªæ¡ä»¶
        content_review_needed = False
        
        # 1. é…å»¶ç†ç”±ãŒ15ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã•ã‚Œãªã„ï¼ˆé‡å¤§å•é¡Œï¼‰
        delay_reasons = llm_result.get('delay_reasons', [])
        for delay_reason in delay_reasons:
            if delay_reason.get('category') == 'é‡å¤§å•é¡Œï¼ˆè¦äººçš„ç¢ºèªï¼‰':
                content_review_needed = True
                break
        
        # 2. å¿…é ˆé …ç›®ãŒå–å¾—ã§ããªã‹ã£ãŸ
        missing_required_fields = self._check_required_fields(report, llm_result)
        if missing_required_fields:
            content_review_needed = True
            # validation_issuesã«è¿½åŠ 
            for field in missing_required_fields:
                if f"å¿…é ˆé …ç›®ä¸è¶³: {field}" not in report.validation_issues:
                    report.validation_issues.append(f"å¿…é ˆé …ç›®ä¸è¶³: {field}")
        
        # æ—¢å­˜ã®validation_issuesã‚‚ãƒã‚§ãƒƒã‚¯
        if report.validation_issues:
            content_review_needed = True
        
        # 3. LLMãŒåˆ†æå›°é›£ã¨åˆ¤å®š
        if report.requires_human_review:
            content_review_needed = True
        
        # 4. åˆ†æä¿¡é ¼åº¦ãŒä½ã„
        if report.analysis_confidence < 0.7:
            content_review_needed = True
        
        report.requires_content_review = content_review_needed
        
        # æ¡ˆä»¶ã¨ã®ç´ã¥ã‘ç¢ºèªãŒå¿…è¦ãªæ¡ä»¶
        mapping_review_needed = False
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ãŒå¤±æ•—ã¾ãŸã¯ä½ä¿¡é ¼åº¦
        if hasattr(report, 'project_mapping_info') and report.project_mapping_info:
            method = report.project_mapping_info.get('matching_method', 'unknown')
            if method == 'vector_search':
                # ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã®å ´åˆã¯ä¿¡é ¼åº¦ã«é–¢ã‚ã‚‰ãšç¢ºèªãŒå¿…è¦
                mapping_review_needed = True
            elif method in ['mapping_failed', 'vector_search_unavailable']:
                mapping_review_needed = True
        
        report.requires_mapping_review = mapping_review_needed
    
    def _check_required_fields(self, report: DocumentReport, llm_result: Dict[str, Any]) -> List[str]:
        """å¿…é ˆé …ç›®ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ä¸è¶³ã—ã¦ã„ã‚‹é …ç›®ã‚’è¿”ã™"""
        missing_fields = []
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‹ã‚‰å–å¾—
        project_info = llm_result.get('project_info', {})
        
        # å¿…é ˆé …ç›®ã®å®šç¾©ï¼ˆæ‹…å½“è€…åã¨åŸºåœ°å±€ç•ªå·ã¯é™¤å¤–ï¼‰
        required_fields = {
            'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID': report.project_id,
            'auRoraãƒ—ãƒ©ãƒ³å': project_info.get('aurora_plan'),
            'åŸºåœ°å±€å': project_info.get('station_name'),
            'ä½æ‰€': project_info.get('location'),
            'å ±å‘Šæ›¸ã‚¿ã‚¤ãƒ—': report.report_type,
            'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': report.status_flag,
            'ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«': report.risk_level,
            'ç·Šæ€¥åº¦ã‚¹ã‚³ã‚¢': getattr(report, 'urgency_score', None)
        }
        
        # å„é …ç›®ã‚’ãƒã‚§ãƒƒã‚¯
        for field_name, value in required_fields.items():
            if value is None or value == 'ä¸æ˜' or value == '':
                missing_fields.append(field_name)
        
        # é…å»¶ç†ç”±ã¯é…å»¶ãŒç™ºç”Ÿã—ã¦ã„ã‚‹å ´åˆã®ã¿å¿…é ˆ
        if report.status_flag and report.status_flag.value in ['minor_delay', 'major_delay', 'stopped']:
            delay_reasons = getattr(report, 'delay_reasons', [])
            if not delay_reasons:
                missing_fields.append('é…å»¶ç†ç”±')
        
        return missing_fields
    
    def _add_to_vector_store(self, report: DocumentReport) -> bool:
        """ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«æ–‡æ›¸ã‚’è¿½åŠ """
        metadata = {
            'file_name': report.file_name,
            'file_path': report.file_path,
            'report_type': report.report_type.value,
            'created_at': report.created_at.isoformat(),
            'risk_level': report.risk_level.value if report.risk_level else 'ä½',
            'urgency_score': getattr(report, 'urgency_score', 1)
        }
        
        return self.vector_store.add_document(report.content, metadata)
    
    def _apply_project_mapping(self, report: DocumentReport, llm_result: Dict[str, Any]):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ï¼ˆæ¡ä»¶ä»˜ããƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼‰"""
        try:
            # ğŸš€ 1. LLMç›´æ¥IDæŠ½å‡ºã‚’æœ€å„ªå…ˆã§è©¦è¡Œ
            project_info = llm_result.get('project_info', {})
            direct_project_id = project_info.get('project_id')
            
            if direct_project_id and direct_project_id != 'ä¸æ˜':
                # LLMã‹ã‚‰ç›´æ¥IDãŒå–å¾—ã§ããŸå ´åˆã¯ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ—
                report.project_id = direct_project_id
                report.project_mapping_info = {
                    'confidence_score': project_info.get('project_id_confidence', 0.8),
                    'matching_method': 'llm_direct',
                    'alternative_candidates': [],
                    'extracted_info': {'llm_id': direct_project_id, 'llm_confidence': project_info.get('project_id_confidence', 0.8)}
                }
                logger.info(f"LLM direct project_id mapping: {direct_project_id} for {report.file_name}")
                return
            
            # ğŸ” 2. ç›´æ¥IDãŒå–å¾—ã§ããªã„å ´åˆã®ã¿ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢
            logger.info(f"Direct ID not found, using vector search for {report.file_name}")
            from app.services.project_mapper import ProjectMapper
            
            project_mapper = ProjectMapper()
            mapping_result = project_mapper.map_project(report.content, llm_result)
            
            if mapping_result.project_id:
                report.project_id = mapping_result.project_id
                logger.info(f"Vector search project_id: {mapping_result.project_id} "
                          f"(confidence: {mapping_result.confidence_score:.2f}) for {report.file_name}")
                
                # ãƒãƒƒãƒ”ãƒ³ã‚°è©³ç´°æƒ…å ±ã‚’ä¿å­˜
                report.project_mapping_info = {
                    'confidence_score': mapping_result.confidence_score,
                    'matching_method': mapping_result.matching_method,
                    'alternative_candidates': mapping_result.alternative_candidates,
                    'extracted_info': mapping_result.extracted_info
                }
                
                # ä½ä¿¡é ¼åº¦ã®å ´åˆã¯æ¤œè¨¼ãŒå¿…è¦ã¨ã—ã¦ãƒãƒ¼ã‚¯
                if mapping_result.confidence_score < 0.7:
                    report.has_unexpected_values = True
                    report.validation_issues.append(f"ä½ä¿¡é ¼åº¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°: {mapping_result.confidence_score:.2f}")
                    
            else:
                report.project_id = None
                logger.warning(f"Failed to map project for {report.file_name}")
                report.has_unexpected_values = True
                report.validation_issues.append("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°å¤±æ•—")
                
        except Exception as e:
            logger.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°å¤±æ•—: {e}")
            report.project_id = None
            report.has_unexpected_values = True
            report.validation_issues.append(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
    

    
