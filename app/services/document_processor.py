"""
æ–‡æ›¸å‡¦ç†ã‚µãƒ¼ãƒ“ã‚¹
"""
import os
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
from docx import Document
try:
    import PyPDF2
except ImportError:
    try:
        import pypdf as PyPDF2
    except ImportError:
        PyPDF2 = None

from openpyxl import load_workbook

from app.models.report import DocumentReport, ReportType, AnalysisResult, AnomalyDetection
from app.services.llm_service import LLMService
from app.services.vector_store import VectorStoreService
from app.config.settings import SHAREPOINT_DOCS_DIR

logger = logging.getLogger(__name__)

if PyPDF2 is None:
    logger.warning("PyPDF2/pypdf not available. PDF reading will be disabled.")

def calculate_risk_level_enum(urgency_score: int) -> 'RiskLevel':
    """urgency_scoreã‹ã‚‰è¡¨ç¤ºç”¨ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’ç®—å‡º"""
    from app.models.report import RiskLevel
    if urgency_score >= 7:
        return RiskLevel.HIGH
    elif urgency_score >= 4:
        return RiskLevel.MEDIUM
    else:
        return RiskLevel.LOW

class DocumentProcessor:
    """æ–‡æ›¸å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, llm_provider: Optional[str] = None, create_vector_store: bool = False):
        self.llm_service = LLMService(provider=llm_provider)
        self.vector_store = VectorStoreService(create_mode=create_vector_store)
        
    def process_directory(self, directory_path: Path) -> List[DocumentReport]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨æ–‡æ›¸ã‚’å‡¦ç†"""
        reports = []
        
        # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
        supported_extensions = {'.txt', '.pdf', '.docx', '.xlsx'}
        
        for file_path in directory_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                try:
                    report = self.process_single_document(file_path)
                    if report:
                        reports.append(report)
                        logger.info(f"Processed: {file_path.name}")
                except Exception as e:
                    logger.error(f"Failed to process {file_path}: {e}")
        
        return reports
    
    def process_single_document(self, file_path: Path) -> Optional[DocumentReport]:
        """å˜ä¸€æ–‡æ›¸ã‚’å‡¦ç†ï¼ˆçµ±åˆåˆ†æ1å›ã®ã¿ï¼‰"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
            content = self._read_file_content(file_path)
            if not content:
                return None
            
            # ğŸ¤– çµ±åˆLLMåˆ†æã‚’å®Ÿè¡Œï¼ˆãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—åˆ¤å®š + ãƒ¡ã‚¤ãƒ³åˆ†æ + åˆ†é¡å›°é›£æ¤œçŸ¥ã‚’1å›ã§ï¼‰
            llm_result = self.llm_service.analyze_document(content)
            if not llm_result:
                logger.error(f"çµ±åˆLLMåˆ†æãŒå¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ãªã—ï¼‰: {file_path.name}")
                return None
            
            # DocumentReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆï¼ˆçµ±åˆåˆ†æçµæœã‚’ä½¿ç”¨ï¼‰
            report = self._create_report_from_unified_analysis(file_path, content, llm_result)
            
            # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
            self._add_to_vector_store(report)
            
            return report
            
        except Exception as e:
            logger.error(f"Document processing failed: {e}")
            return None
    
    def _read_file_content(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿"""
        extension = file_path.suffix.lower()
        
        try:
            if extension == '.txt':
                return self._read_text_file(file_path)
            elif extension == '.pdf':
                return self._read_pdf_file(file_path)
            elif extension == '.docx':
                return self._read_docx_file(file_path)
            elif extension == '.xlsx':
                return self._read_xlsx_file(file_path)
            else:
                logger.warning(f"Unsupported file type: {extension}")
                return ""
        except Exception as e:
            logger.error(f"Failed to read file {file_path}: {e}")
            return ""
    
    def _read_text_file(self, file_path: Path) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        encodings = ['utf-8', 'shift_jis', 'euc-jp', 'iso-2022-jp']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue
        
        # ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§å¤±æ•—ã—ãŸå ´åˆ
        logger.warning(f"Could not decode text file: {file_path}")
        return ""
    
    def _read_pdf_file(self, file_path: Path) -> str:
        """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if PyPDF2 is None:
            logger.warning(f"PDF reading not available for {file_path}")
            return "PDFèª­ã¿è¾¼ã¿æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚PyPDF2ã¾ãŸã¯pypdfã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚"
        
        text = ""
        try:
            with open(file_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\\n"
        except Exception as e:
            logger.error(f"PDF reading failed: {e}")
        return text
    
    def _read_docx_file(self, file_path: Path) -> str:
        """Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ±ç”¨çš„ï¼‰"""
        text = ""
        try:
            doc = Document(file_path)
            
            # æ®µè½ã‚’èª­ã¿è¾¼ã¿
            for paragraph in doc.paragraphs:
                para_text = paragraph.text.strip()
                if para_text:
                    # ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                    para_text = para_text.replace('\\t', ' ')
                    para_text = ' '.join(para_text.split())  # è¤‡æ•°ç©ºç™½ã‚’1ã¤ã«
                    text += para_text + "\\n"
            
            # è¡¨ã‚’èª­ã¿è¾¼ã¿
            for table in doc.tables:
                text += "\\nè¡¨:\\n"
                for row in table.rows:
                    row_data = []
                    for cell in row.cells:
                        cell_text = cell.text.strip()
                        if cell_text:
                            # ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                            cell_text = cell_text.replace('\\n', ' ').replace('\\t', ' ')
                            cell_text = ' '.join(cell_text.split())  # è¤‡æ•°ç©ºç™½ã‚’1ã¤ã«
                            if cell_text not in ['', '-', 'âˆ’', 'è©²å½“ãªã—', 'ãªã—']:
                                row_data.append(cell_text)
                    if row_data:
                        text += " | ".join(row_data) + "\\n"
                        
        except Exception as e:
            logger.error(f"DOCX reading failed: {e}")
        return text
    
    def _read_xlsx_file(self, file_path: Path) -> str:
        """Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ±ç”¨çš„ï¼‰"""
        text = ""
        try:
            workbook = load_workbook(file_path, data_only=True)
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                text += f"\\nã‚·ãƒ¼ãƒˆ: {sheet_name}\\n"
                
                # å…¨ã‚»ãƒ«ã®å†…å®¹ã‚’é †æ¬¡æŠ½å‡º
                for row in sheet.iter_rows(values_only=True):
                    row_values = []
                    for cell_value in row:
                        if cell_value is not None:
                            # ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                            clean_value = str(cell_value).strip()
                            # ä¸è¦æ–‡å­—ã®å‰Šé™¤ï¼ˆæ”¹è¡Œã€ã‚¿ãƒ–ã€ä½™åˆ†ãªç©ºç™½ï¼‰
                            clean_value = clean_value.replace('\\n', ' ').replace('\\t', ' ')
                            clean_value = ' '.join(clean_value.split())  # è¤‡æ•°ç©ºç™½ã‚’1ã¤ã«
                            # ç©ºæ–‡å­—ã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                            if clean_value and clean_value not in ['nan', 'None', 'NULL', '#N/A']:
                                row_values.append(clean_value)
                    
                    if row_values:
                        text += " | ".join(row_values) + "\\n"
                        
        except Exception as e:
            logger.error(f"XLSX reading failed: {e}")
        return text
    
    def _create_report_from_unified_analysis(self, file_path: Path, content: str, llm_result: Dict[str, Any]) -> DocumentReport:
        """çµ±åˆLLMåˆ†æçµæœã‹ã‚‰DocumentReportã‚’ä½œæˆ"""
        from app.models.report import StatusFlag, RiskLevel
        from app.services.project_mapper import ProjectMapper
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã®è¨­å®š
        report_type_str = llm_result.get('report_type', 'OTHER')
        try:
            report_type = ReportType(report_type_str)
        except ValueError:
            logger.warning(f"ç„¡åŠ¹ãªãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—: {report_type_str}ã€OTHERã«è¨­å®š")
            report_type = ReportType.OTHER
        
        # DocumentReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        report = DocumentReport(
            file_path=str(file_path),
            file_name=file_path.name,
            report_type=report_type,
            content=content,
            created_at=datetime.fromtimestamp(file_path.stat().st_mtime)
        )
        
        # ğŸ¤– çµ±åˆåˆ†æçµæœã‚’è¨­å®š
        report.requires_human_review = llm_result.get('requires_human_review', False)
        report.analysis_confidence = llm_result.get('analysis_confidence', 0.0)
        report.analysis_notes = llm_result.get('analysis_notes', '')
        
        # ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆç›´æ¥ID + ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼‰
        self._apply_project_mapping(report, llm_result)
        
        # ğŸ·ï¸ æ–°ãƒ•ãƒ©ã‚°ä½“ç³»ã®é©ç”¨ï¼ˆç°¡ç•¥åŒ–ï¼‰
        # StatusFlagè¨­å®šï¼ˆLLMã‹ã‚‰ç›´æ¥å–å¾—ï¼‰
        llm_status_flag = llm_result.get('status_flag')
        if llm_status_flag:
            if llm_status_flag == 'åœæ­¢':
                report.status_flag = StatusFlag.STOPPED
            elif llm_status_flag == 'é‡å¤§ãªé…å»¶':
                report.status_flag = StatusFlag.MAJOR_DELAY
            elif llm_status_flag == 'è»½å¾®ãªé…å»¶':
                report.status_flag = StatusFlag.MINOR_DELAY
            elif llm_status_flag == 'é †èª¿':
                report.status_flag = StatusFlag.NORMAL
            else:
                report.status_flag = StatusFlag.NORMAL
        else:
            report.status_flag = StatusFlag.NORMAL
            
        # RiskLevelè¨­å®šï¼ˆurgency_scoreã‹ã‚‰é€£å‹•ãƒ«ãƒ¼ãƒ«ã§ç®—å‡ºï¼‰
        urgency_score = llm_result.get('urgency_score', 1)
        report.urgency_score = urgency_score
        report.risk_level = calculate_risk_level_enum(urgency_score)
        
        # ğŸ” å»ºè¨­å·¥ç¨‹æƒ…å ±ã®è¨­å®š
        report.current_construction_phase = llm_result.get('construction_phase', 'ä¸æ˜')
        report.construction_progress = llm_result.get('construction_progress', {})
        
        # ğŸš§ é…å»¶ç†ç”±æƒ…å ±ã®è¨­å®šï¼ˆ15ã‚«ãƒ†ã‚´ãƒªä½“ç³»ï¼‰
        report.delay_reasons = llm_result.get('delay_reasons', [])
        
        # current_statuså‡¦ç†å‰Šé™¤: status_flagã§çµ±ä¸€
        
        # ğŸ“‹ AnalysisResultä½œæˆï¼ˆç°¡ç´ åŒ–ï¼‰
        report.analysis_result = AnalysisResult(
            summary=llm_result.get('summary', 'åˆ†æçµæœãªã—'),
            issues=llm_result.get('issues', []),
            key_points=llm_result.get('key_points', []),
            confidence=report.analysis_confidence
        )
        
        # ğŸš¨ ç•°å¸¸æ¤œçŸ¥ã®çµ±åˆï¼ˆåˆ†æå›°é›£åº¦ã¨ã—ã¦æ‰±ã†ï¼‰
        report.anomaly_detection = AnomalyDetection(
            is_anomaly=report.requires_human_review,
            anomaly_description=f"LLMã«ã‚ˆã‚‹åˆ†æå›°é›£åº¦: {'è¦ç¢ºèª' if report.requires_human_review else 'æ­£å¸¸'}",
            confidence=report.analysis_confidence,
            suggested_action="æ‰‹å‹•ç¢ºèªã‚’æ¨å¥¨" if report.requires_human_review else "è‡ªå‹•åˆ†æå®Œäº†",
            requires_human_review=report.requires_human_review,
            similar_cases=[]
        )
        
        return report
    
    def _add_to_vector_store(self, report: DocumentReport) -> bool:
        """ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«æ–‡æ›¸ã‚’è¿½åŠ """
        metadata = {
            'file_name': report.file_name,
            'file_path': report.file_path,
            'report_type': report.report_type.value,
            'created_at': report.created_at.isoformat(),
            'risk_level': report.risk_level.value if report.risk_level else 'ä½',
            'urgency_score': getattr(report, 'urgency_score', 1)
        }
        
        return self.vector_store.add_document(report.content, metadata)
    
    def _apply_project_mapping(self, report: DocumentReport, llm_result: Dict[str, Any]):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ï¼ˆç›´æ¥ID + ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼‰"""
        try:
            from app.services.project_mapper import ProjectMapper
            
            # ğŸ¯ ãƒãƒ«ãƒæˆ¦ç•¥ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°
            project_mapper = ProjectMapper()
            mapping_result = project_mapper.map_project(report.content, llm_result)
            
            if mapping_result.project_id:
                report.project_id = mapping_result.project_id
                logger.info(f"Mapped project_id: {mapping_result.project_id} "
                          f"(confidence: {mapping_result.confidence_score:.2f}, "
                          f"method: {mapping_result.matching_method}) for {report.file_name}")
                
                # ãƒãƒƒãƒ”ãƒ³ã‚°è©³ç´°æƒ…å ±ã‚’ä¿å­˜
                report.project_mapping_info = {
                    'confidence_score': mapping_result.confidence_score,
                    'matching_method': mapping_result.matching_method,
                    'alternative_candidates': mapping_result.alternative_candidates,
                    'extracted_info': mapping_result.extracted_info
                }
                
                # ä½ä¿¡é ¼åº¦ã®å ´åˆã¯æ¤œè¨¼ãŒå¿…è¦ã¨ã—ã¦ãƒãƒ¼ã‚¯
                if mapping_result.confidence_score < 0.7:
                    report.has_unexpected_values = True
                    report.validation_issues.append(f"ä½ä¿¡é ¼åº¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°: {mapping_result.confidence_score:.2f}")
                    
            else:
                report.project_id = None
                logger.warning(f"Failed to map project for {report.file_name}")
                report.has_unexpected_values = True
                report.validation_issues.append("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°å¤±æ•—")
                
        except Exception as e:
            logger.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°å¤±æ•—: {e}")
            report.project_id = None
            report.has_unexpected_values = True
            report.validation_issues.append(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
