"""
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹
"""

import re
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
# from difflib import SequenceMatcher  # ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°å»ƒæ­¢ã®ãŸã‚ä¸è¦
import logging

# ãƒ™ã‚¯ã‚¿ãƒ¼ãƒãƒƒãƒ‘ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
try:
    from .project_vector_mapper import ProjectVectorMapper
    VECTOR_SEARCH_AVAILABLE = True
except ImportError:
    VECTOR_SEARCH_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class ProjectMapping:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°çµæœ"""
    project_id: Optional[str]
    confidence_score: float
    matching_method: str
    alternative_candidates: List[str]
    extracted_info: Dict[str, str]

class ProjectMapper:
    """ãƒãƒ«ãƒæˆ¦ç•¥ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.project_master = self._load_project_master()
        self.location_patterns = self._build_location_patterns()
        
        # ãƒ™ã‚¯ã‚¿ãƒ¼ãƒãƒƒãƒ‘ãƒ¼åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
        self.vector_mapper = None
        logger.info(f"VECTOR_SEARCH_AVAILABLE: {VECTOR_SEARCH_AVAILABLE}")
        if VECTOR_SEARCH_AVAILABLE:
            try:
                self.vector_mapper = ProjectVectorMapper()
                logger.info("Vector search enabled successfully")
            except Exception as e:
                logger.error(f"Failed to initialize vector mapper: {e}")
                self.vector_mapper = None
        else:
            logger.warning("Vector search module not available (import failed)")
        
    def _load_project_master(self) -> List[Dict]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            master_file = Path("data/sample_construction_data/project_reports_mapping.json")
            if master_file.exists():
                with open(master_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return []
        except Exception as e:
            logger.error(f"Failed to load project master: {e}")
            return []
    
    def _build_location_patterns(self) -> Dict[str, List[str]]:
        """å ´æ‰€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰"""
        patterns = {}
        for project in self.project_master:
            location = project.get('location', '')
            project_id = project.get('project_id', '')
            project_name = project.get('project_name', '')
            
            # å ´æ‰€ã®æ­£è¦åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
            location_variants = [
                location,
                location.replace('éƒ½', '').replace('çœŒ', '').replace('å¸‚', '').replace('åŒº', ''),
                # ä¾‹: "æ±äº¬éƒ½å“å·åŒº" -> ["æ±äº¬éƒ½å“å·åŒº", "å“å·", "å“å·åŒº"]
            ]
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰ã®å ´æ‰€æŠ½å‡º
            name_locations = self._extract_locations_from_name(project_name)
            location_variants.extend(name_locations)
            
            for variant in location_variants:
                if variant and len(variant) > 1:
                    if variant not in patterns:
                        patterns[variant] = []
                    patterns[variant].append(project_id)
                    
        return patterns
    
    def _extract_locations_from_name(self, project_name: str) -> List[str]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰å ´æ‰€ã‚’æŠ½å‡º"""
        locations = []
        
        # éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘ãƒ‘ã‚¿ãƒ¼ãƒ³
        prefecture_pattern = r'(æ±äº¬éƒ½|ç¥å¥ˆå·çœŒ|åŸ¼ç‰çœŒ|åƒè‘‰çœŒ|å¤§é˜ªåºœ|äº¬éƒ½åºœ|å…µåº«çœŒ|å¥ˆè‰¯çœŒ|å’Œæ­Œå±±çœŒ|æ„›çŸ¥çœŒ|é™å²¡çœŒ|å²é˜œçœŒ|ä¸‰é‡çœŒ|åŒ—æµ·é“|é’æ£®çœŒ|å²©æ‰‹çœŒ|å®®åŸçœŒ|ç§‹ç”°çœŒ|å±±å½¢çœŒ|ç¦å³¶çœŒ|èŒ¨åŸçœŒ|æ ƒæœ¨çœŒ|ç¾¤é¦¬çœŒ|æ–°æ½ŸçœŒ|å¯Œå±±çœŒ|çŸ³å·çœŒ|ç¦äº•çœŒ|å±±æ¢¨çœŒ|é•·é‡çœŒ|æ»‹è³€çœŒ|åºƒå³¶çœŒ|å±±å£çœŒ|å¾³å³¶çœŒ|é¦™å·çœŒ|æ„›åª›çœŒ|é«˜çŸ¥çœŒ|ç¦å²¡çœŒ|ä½è³€çœŒ|é•·å´çœŒ|ç†Šæœ¬çœŒ|å¤§åˆ†çœŒ|å®®å´çœŒ|é¹¿å…å³¶çœŒ|æ²–ç¸„çœŒ)'
        city_pattern = r'([^\s]+å¸‚|[^\s]+åŒº|[^\s]+ç”º|[^\s]+æ‘)'
        
        # éƒ½é“åºœçœŒæŠ½å‡º
        prefecture_matches = re.findall(prefecture_pattern, project_name)
        locations.extend(prefecture_matches)
        
        # å¸‚åŒºç”ºæ‘æŠ½å‡º
        city_matches = re.findall(city_pattern, project_name)
        locations.extend(city_matches)
        
        return locations
    
    def map_project(self, report_content: str, llm_extracted_info: Dict) -> ProjectMapping:
        """
        ã‚·ãƒ³ãƒ—ãƒ«ãª2æ®µéšãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°
        
        1. ç›´æ¥IDæŠ½å‡ºï¼ˆLLMã®ã¿ã€æˆåŠŸæ™‚ã¯ä¿¡é ¼åº¦100%ï¼‰
        2. ãƒ™ã‚¯ã‚¿ãƒ¼ã‚µãƒ¼ãƒï¼ˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€ä¿¡é ¼åº¦=é¡ä¼¼åº¦ï¼‰
        """
        
        # æˆ¦ç•¥1: ç›´æ¥IDæŠ½å‡ºï¼ˆLLMã®ã¿ï¼‰
        direct_mapping = self._strategy_direct_id_extraction(report_content, llm_extracted_info)
        if direct_mapping.project_id:  # IDãŒæŠ½å‡ºã§ããŸå ´åˆ
            logger.info(f"Direct ID mapping successful: {direct_mapping.project_id}")
            return direct_mapping
        
        # æˆ¦ç•¥2: ãƒ™ã‚¯ã‚¿ãƒ¼ã‚µãƒ¼ãƒï¼ˆç›´æ¥IDå¤±æ•—æ™‚ã®ã¿ï¼‰
        if self.vector_mapper:
            vector_mapping = self._strategy_vector_search(report_content, llm_extracted_info)
            logger.info(f"Vector search completed: {vector_mapping.project_id} (confidence: {vector_mapping.confidence_score:.3f})")
            return vector_mapping
        else:
            logger.warning(f"Vector search unavailable, returning failed direct mapping. VECTOR_SEARCH_AVAILABLE: {VECTOR_SEARCH_AVAILABLE}")
            # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚µãƒ¼ãƒãŒåˆ©ç”¨ã§ããªã„å ´åˆã§ã‚‚ã€ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€åˆã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™
            if self.project_master:
                fallback_project = self.project_master[0]
                logger.info(f"Using fallback project: {fallback_project['project_id']}")
                return ProjectMapping(
                    project_id=fallback_project['project_id'],
                    confidence_score=0.1,  # ä½ã„ä¿¡é ¼åº¦
                    matching_method="fallback_first_project",
                    alternative_candidates=[],
                    extracted_info={"reason": "Vector search unavailable, using fallback"}
                )
            return direct_mapping
    
    def _strategy_direct_id_extraction(self, content: str, llm_info: Dict) -> ProjectMapping:
        """æˆ¦ç•¥1: ç›´æ¥IDæŠ½å‡ºï¼ˆLLMã®ã¿ï¼‰"""
        
        # LLMã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸproject_idã‚’ãƒã‚§ãƒƒã‚¯
        llm_project_id = None
        if 'project_info' in llm_info and llm_info['project_info']:
            llm_project_id = llm_info['project_info'].get('project_id', '').strip()
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒã‚¹ã‚¿ãƒ¼ã¨ã®ç…§åˆ
        master_ids = [p['project_id'] for p in self.project_master]
        
        # LLMæŠ½å‡ºIDã®æ¤œè¨¼
        if llm_project_id and llm_project_id != "ä¸æ˜":
            if llm_project_id in master_ids:
                return ProjectMapping(
                    project_id=llm_project_id,
                    confidence_score=1.0,  # 100%ï¼ˆãƒ€ãƒŸãƒ¼å€¤ï¼‰
                    matching_method="llm_direct",
                    alternative_candidates=[],
                    extracted_info={"llm_extracted_id": llm_project_id}
                )
        
        # æŠ½å‡ºå¤±æ•—
        return ProjectMapping(
            project_id=None,
            confidence_score=0.0,
            matching_method="direct_id_failed",
            alternative_candidates=[],
            extracted_info={
                "llm_extracted_id": llm_project_id,
                "reason": "LLMãŒä¸æ˜ã‚’è¿”ã™ã‹ãƒã‚¹ã‚¿ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã«å­˜åœ¨ã—ãªã„"
            }
        )
    
    # ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°å‰Šé™¤ï¼šã‚·ãƒ³ãƒ—ãƒ«ãª2æ®µéšæ–¹å¼ã®ãŸã‚ä¸è¦
    
    def _extract_locations_from_content(self, content: str) -> List[str]:
        """æ–‡æ›¸å†…å®¹ã‹ã‚‰å ´æ‰€ã‚’æŠ½å‡º"""
        locations = []
        
        # å ´æ‰€ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        location_patterns = [
            r'å ´æ‰€[ï¼š:\s]*([^\n\r]+)',
            r'æ‰€åœ¨åœ°[ï¼š:\s]*([^\n\r]+)',
            r'å·¥äº‹å ´æ‰€[ï¼š:\s]*([^\n\r]+)',
            r'å»ºè¨­åœ°[ï¼š:\s]*([^\n\r]+)',
        ]
        
        for pattern in location_patterns:
            matches = re.findall(pattern, content)
            locations.extend([m.strip() for m in matches if m.strip()])
        
        # éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘ã®è‡ªå‹•æŠ½å‡º
        locations.extend(self._extract_locations_from_name(content))
        
        return list(set(locations))  # é‡è¤‡é™¤å»
    
    def _extract_project_names_from_content(self, content: str) -> List[str]:
        """æ–‡æ›¸å†…å®¹ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’æŠ½å‡º"""
        names = []
        
        name_patterns = [
            r'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå[ï¼š:\s]*([^\n\r]+)',
            r'å·¥äº‹å[ï¼š:\s]*([^\n\r]+)',
            r'æ¡ˆä»¶å[ï¼š:\s]*([^\n\r]+)',
            r'å»ºè¨­å·¥äº‹[ï¼š:\s]*([^\n\r]+)',
            r'å±€å[ï¼š:\s]*([^\n\r]+)',
            r'auRoraãƒ—ãƒ©ãƒ³å[ï¼š:\s]*([^\n\r]+)',
            r'ãƒ—ãƒ©ãƒ³å[ï¼š:\s]*([^\n\r]+)',
            r'å±€ç•ª[ï¼š:\s]*([^\n\r]+)',
        ]
        
        for pattern in name_patterns:
            matches = re.findall(pattern, content)
            names.extend([m.strip() for m in matches if m.strip()])
        
        return names
    
    # é¡ä¼¼åº¦è¨ˆç®—é–¢æ•°å‰Šé™¤ï¼šãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°å»ƒæ­¢ã®ãŸã‚ä¸è¦
    
    def _strategy_vector_search(self, content: str, llm_info: Dict) -> ProjectMapping:
        """æˆ¦ç•¥3: ãƒ™ã‚¯ã‚¿ãƒ¼ã‚µãƒ¼ãƒã«ã‚ˆã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒãƒ³ã‚°ï¼ˆæ”¹å–„ç‰ˆï¼šLLMæŠ½å‡ºæƒ…å ±ã®ã¿ä½¿ç”¨ï¼‰"""
        
        if not self.vector_mapper:
            return ProjectMapping(
                project_id=None,
                confidence_score=0.0,
                matching_method="vector_search_unavailable",
                alternative_candidates=[],
                extracted_info={}
            )
        
        try:
            # æ¤œç´¢ã‚¯ã‚¨ãƒªä½œæˆï¼ˆLLMæŠ½å‡ºæƒ…å ±ã®ã¿ä½¿ç”¨ï¼‰
            query_parts = []
            
            # LLMæŠ½å‡ºæƒ…å ±ã‹ã‚‰è¿½åŠ ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒã‚¹ã‚¿ãƒ¼ã¨åŒã˜æ§‹é€ ï¼‰
            if 'project_info' in llm_info and llm_info['project_info']:
                project_info = llm_info['project_info']
                
                # å„ªå…ˆåº¦é †ã«è¿½åŠ 
                if project_info.get('station_name'):
                    query_parts.append(f"å±€å: {project_info['station_name']}")
                
                if project_info.get('location'):
                    query_parts.append(f"å ´æ‰€: {project_info['location']}")
                
                if project_info.get('station_number'):
                    query_parts.append(f"å±€ç•ª: {project_info['station_number']}")
                
                if project_info.get('aurora_plan'):
                    query_parts.append(f"Auroraè¨ˆç”»: {project_info['aurora_plan']}")
                
                if project_info.get('responsible_person'):
                    query_parts.append(f"æ‹…å½“è€…: {project_info['responsible_person']}")
            
            query_text = " ".join(query_parts)  # LLMæŠ½å‡ºæƒ…å ±ã®ã¿
            
            if not query_text.strip():
                return ProjectMapping(
                    project_id=None,
                    confidence_score=0.0,
                    matching_method="vector_search_no_query",
                    alternative_candidates=[],
                    extracted_info={}
                )
            
            # ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢å®Ÿè¡Œï¼ˆé–¾å€¤0.0ã§å¿…ãšæœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰
            search_results = self.vector_mapper.search_similar_projects(
                query_text=query_text,
                top_k=5,
                similarity_threshold=0.0  # é–¾å€¤0.0ã§å¿…ãšãƒãƒƒãƒ”ãƒ³ã‚°
            )
            
            if search_results:
                best_result = search_results[0]
                
                # ğŸ†• è©³ç´°ãªæ ¹æ‹ ç”Ÿæˆ
                reasoning = self.vector_mapper.generate_search_reasoning(query_text, search_results)
                
                # ä¿¡é ¼åº¦ = ãƒ™ã‚¯ã‚¿ãƒ¼é¡ä¼¼åº¦ãã®ã¾ã¾
                confidence = reasoning.get("confidence", best_result.similarity_score)
                
                return ProjectMapping(
                    project_id=best_result.project_id,
                    confidence_score=confidence,
                    matching_method="vector_search",
                    alternative_candidates=[r.project_id for r in search_results[1:3]],
                    extracted_info={
                        "query_text": query_text,
                        "vector_similarity": best_result.similarity_score,
                        "matched_keywords": best_result.matched_keywords,
                        # ğŸ†• è©³ç´°ãªæ ¹æ‹ æƒ…å ±
                        "reasoning": reasoning.get("reason", ""),
                        "matched_elements": reasoning.get("matched_elements", []),
                        "fuzzy_matches": reasoning.get("fuzzy_matches", []),
                        "project_name": reasoning.get("project_name", "ä¸æ˜")
                    }
                )
            
            return ProjectMapping(
                project_id=None,
                confidence_score=0.0,
                matching_method="vector_search_no_match",
                alternative_candidates=[],
                extracted_info={"query_text": query_text}
            )
            
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return ProjectMapping(
                project_id=None,
                confidence_score=0.0,
                matching_method="vector_search_error",
                alternative_candidates=[],
                extracted_info={"error": str(e)}
            )